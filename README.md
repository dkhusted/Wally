# Wally
> A tiny helper

## Table of Contents
* [General Info](#general-information)
* [Technologies Used](#technologies-used)
* [Features](#features)
* [Setup](#setup)
* [Usage](#usage)
* [Project Status](#project-status)
* [Room for Improvement](#room-for-improvement)
* [Acknowledgements](#acknowledgements)
* [Contact](#contact)
<!-- * [License](#license) -->


## General Information
- The project propose an different approch to smart homes. Instead of using voice commands to get different kinds of information via a traditional smart-home device, like Alexy or Google Home, Wally will use sign language to determine the user request. 
- The reason for this is to inable people with the mute dissability to also have access to an smart home device, and that image processing would be more reliable than audio since bagground noice, such as other people or tv, would not have an effect. The only noice factor would be the light level.
<!-- You don't have to answer all the questions - just the ones relevant to your project. -->


## Technologies Used


## Features
List the ready features here:


## Setup

## Usage
How does one go about using it?
Provide various use cases and code examples here.

`write-your-code-here`


## Project Status
Project is: _in_definement

## Acknowledgements


## Contact
Created by [@dkhusted] - feel free to contact me!


<!-- Optional -->
<!-- ## License -->
<!-- This project is open source and available under the [... License](). -->

<!-- You don't have to include all sections - just the one's relevant to your project -->
